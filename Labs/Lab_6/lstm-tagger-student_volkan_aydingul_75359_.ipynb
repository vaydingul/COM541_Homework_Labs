{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP541 - LAB\n",
    "## LSTM Named Entity Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n",
    "\n",
    "Most research on NER systems has been structured as taking an unannotated block of text, such as the following **example**:\n",
    "\n",
    "**INPUT:** Jim bought 300 shares of Acme Corp. in 2006.\n",
    "\n",
    "And producing an annotated block of text that highlights the names of entities:\n",
    "\n",
    "**OUTPUT:** [Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time.\n",
    "\n",
    "In this example, a person name consisting of one token, a two-token company name and a temporal expression have been detected and classified.(Wikipedia)\n",
    "\n",
    "Your task in this lab is to implement named entity LSTM based tagger which uses an LSTM to extract features from the input sentence, which are then passed through a multi-layer perceptron to predict\n",
    "the tag of the word. Finally, train that model on [WikiNER](https://github.com/neulab/dynet-benchmark/tree/master/data/tags) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `/scratch/users/vaydingul20/.julia/environments/v1.5/Manifest.toml`\n",
      "┌ Info: Adding required packages and importing WikiNER dataset\n",
      "└ @ Main In[5]:10\n"
     ]
    }
   ],
   "source": [
    "using Pkg; for p in [\"IterTools\", \"Knet\",\"ArgParse\", \"CUDA\"]; Pkg.add(p); end\n",
    "using Printf, Dates, Random, CUDA, Knet, ArgParse, Test, Base.Iterators, IterTools\n",
    "\n",
    "STDOUT = Base.stdout\n",
    "\n",
    "import Knet: train!\n",
    "include(joinpath(Knet.dir(), \"data\", \"wikiner.jl\"))\n",
    "_atype = CUDA.functional() ? KnetArray{Float32} : Array{Float32}\n",
    "\n",
    "@info \"Adding required packages and importing WikiNER dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare samples for the network\n",
    "Your first task is to prepare instances for the network. We're given with the tokens (words and tags) and we need to make them understandable by our neural network. For this purpose, we build vocabularies (for both words and tags) and construct vocabulary to index dictionaries by using those vocabularies (w2i and t2i, word2index, tag2index). Then, we convert words and tags to indices with the usage of our dictionaries.\n",
    "\n",
    "```julia\n",
    "julia> show_instance() # show instance in not implemented in Knet, it is a hypothetical procedure\n",
    "Inputs sentence:\n",
    "Sent-> That inscribed in the genealogical records of his family is Jiang Zhoutai .\n",
    "NERs-> O    O         O  O   O            O       O  O   O      O  I-PER I-PER   O\n",
    "\n",
    "Timesteps:\n",
    "Time step 1 ---> Inputs: That\n",
    "                 Outputs: O\n",
    "Time step 2 ---> Inputs: inscribed\n",
    "                 Outputs:O\n",
    "Time step 3 ---> Inputs: in\n",
    "                 Outputs: O\n",
    "Time step 4 ---> Inputs: the\n",
    "                 Outputs: O\n",
    "Time step 5 ---> Inputs: genealogical\n",
    "                 Outputs: O\n",
    "Time step 6 ---> Inputs: records  .\n",
    "                 Outputs: O\n",
    "Time step 7 ---> Inputs: of\n",
    "                 Outputs: O\n",
    "Time step 8 ---> Inputs: his\n",
    "                 Outputs: O\n",
    "Time step 9 ---> Inputs: family\n",
    "                 Outputs: O\n",
    "Time step 10 --->Inputs: is\n",
    "                 Outputs: O\n",
    "Time step 11 ---> Inputs: Jiang\n",
    "                  Outputs: I-PER\n",
    "Time step 12 ---> Inputs: Zhoutai\n",
    "                  Outputs: I-PER\n",
    "Time step 13 ---> Inputs: .\n",
    "                  Outputs: O\n",
    "```\n",
    "\n",
    "Our input and output arrays should be integers instead of texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you need to implement `make_instance` function\n",
    "instance is a list of tuples. Each tuple contains a word and the corresponding tag as string.\n",
    "You need to convert them into indices using word to index (w2i) and tag to index (t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing instances\n",
      "└ @ Main In[6]:39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    make_instance(instance, w2i, t2i)\n",
    "\n",
    "Return tuple of two sequences containing inputs and the corresponding outputs respectively.\n",
    "\n",
    "This function does this by converting each input unit in the instance into its corresponding value in w2i, and does the same for output units using t2i.\n",
    "\"\"\"\n",
    "function make_instance(instance, w2i, t2i, unk=UNK)\n",
    "    input = Int[]\n",
    "    output = Int[]\n",
    "    # Your code here\n",
    "    for ins in instance\n",
    "       \n",
    "        # If the word does not exists, add ´_UNK_´\n",
    "        push!(input, get(w2i, ins[1], w2i[unk]))\n",
    "        # It the tag does not exists add ´0´\n",
    "        push!(output, get(t2i, ins[2], 0))\n",
    "        \n",
    "    end\n",
    "        \n",
    "    \n",
    "    return input, output\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   make_instances(data, w2i, t2i)\n",
    "\n",
    "Iterate over `data` and Return `words` and `tags`\n",
    "\"\"\"\n",
    "function make_instances(data, w2i, t2i)\n",
    "    words = []; tags = []\n",
    "    for k = 1:length(data)\n",
    "        this_words, this_tags = make_instance(data[k], w2i, t2i)\n",
    "        push!(words, this_words)\n",
    "        push!(tags, this_tags)\n",
    "    end\n",
    "    return words, tags\n",
    "end\n",
    "\n",
    "@info \"Testing instances\"\n",
    "data = WikiNERData();\n",
    "dev = make_instances(data.dev, data.w2i, data.t2i);\n",
    "@test dev[1][2][3] == 11110\n",
    "@test size.(dev) == ((1696,), (1696,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiNERProcessed\n",
    "This struct contains processed data (e.g words and tags are indices)\n",
    "and necessary variables to prepare minibatches.\n",
    "WikiNERProcessed struct works as a data iterator, which will you implement in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: WikiNERProcessed\n",
      "└ @ Main In[7]:20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct WikiNERProcessed\n",
    "    words\n",
    "    tags\n",
    "    batchsize\n",
    "    ninstances\n",
    "    shuffled\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "   WikiNERProcessed(instances, w2i, t2i; batchsize=16, shuffled=true)\n",
    "\n",
    "Return a WikiNERProcessed object with the given instances\n",
    "\"\"\"\n",
    "function WikiNERProcessed(instances, w2i, t2i; batchsize=16, shuffled=true)\n",
    "    words, tags = make_instances(instances, w2i, t2i)\n",
    "    ninstances = length(words)\n",
    "    return WikiNERProcessed(words, tags, batchsize, ninstances, shuffled)\n",
    "end\n",
    "\n",
    "@info \"WikiNERProcessed\"\n",
    "devdata = WikiNERProcessed(data.dev, data.w2i, data.t2i; shuffled=false);\n",
    "@test devdata.words[1][1] == 8653\n",
    "@test length(devdata.words) == 1696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WikiNERProcessed Iterator\n",
    "Please note that this function returns tuple of two tuples.\n",
    "\n",
    "The first one contains a data batch with words as an input for our model, and tags as the corresponding output, and batchsizes of this batch.\n",
    "Since you will use the RNN callable object in your model.\n",
    "It supports variable length instances in its input.\n",
    "However, you need to prepare your input such as the RNN object can work on it. See `batchSizes` option of the RNN object using `@doc RNN` and Look up `zeros`, `sortperm`, `min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing WikiNERProcessed Iterator\n",
      "└ @ Main In[8]:43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    iterate(d::WikiNERProcessed[, state])\n",
    "\n",
    "Iterate over `d::WikiNERProcessed` object. If `state` is missing, it's the beginning\n",
    "of the whole iteration process.\n",
    "\"\"\"\n",
    "function Base.iterate(d::WikiNERProcessed, state=ifelse(d.shuffled, randperm(d.ninstances), 1:d.ninstances))\n",
    "    # Your code here\n",
    "    # Initialization of the array sturctures\n",
    "    words = Int[]\n",
    "    tags = Int[]\n",
    "    batchsizes = Int[]\n",
    "    \n",
    "    # Get sizes of each sequence\n",
    "    sequence_sizes = getindex.(size.(d.words[state[1:d.batchsize]]), 1)\n",
    "    # Determine the sequence having the highest length\n",
    "    max_sequence_size = maximum(sequence_sizes)\n",
    "    # Sort the sequences and get indexes\n",
    "    size_ixs = sortperm(sequence_sizes)[end:-1:1] # Descending order sequence size indexes\n",
    "    \n",
    "    # Batch construction scheme that is explained in the COMP541 forum\n",
    "    for k in 1:max_sequence_size\n",
    "        cnt = 0\n",
    "        for m in size_ixs\n",
    "            if (k <= sequence_sizes[m])\n",
    "                push!(words, d.words[state[m]][k])\n",
    "                push!(tags, d.tags[state[m]][k])\n",
    "                cnt += 1\n",
    "            else\n",
    "                continue\n",
    "            end\n",
    "           \n",
    "        end\n",
    "        push!(batchsizes, cnt)\n",
    "    end\n",
    "    \n",
    "    # Next state\n",
    "    new_state = state[1+d.batchsize:end]\n",
    "    # Iteration ending criteria\n",
    "    remain = length(new_state)\n",
    "    residue = min(d.batchsize, remain)\n",
    "    residue < d.batchsize && return nothing\n",
    "    \n",
    "    return ((words, tags, batchsizes), new_state)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WikiNERProcessed}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WikiNERProcessed}) = Base.HasEltype()\n",
    "\n",
    "@info \"Testing WikiNERProcessed Iterator\"\n",
    "((words, tags, batchsizes), new_state) = iterate(devdata);\n",
    "@test length.((words, tags, batchsizes)) == (397, 397, 55)\n",
    "\n",
    "counter = 1;\n",
    "for ddd in devdata\n",
    "    counter+=1;\n",
    "end\n",
    "\n",
    "@test new_state == 17:1696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Components implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer\n",
    "This layer maps each vocabulary to its corresponding vector using its Int id. It works with mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing embedding layer\n",
      "└ @ Main In[9]:30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Embedding(vocabsize::Int, embedsize::Int, atype=_atype, scale=0.01)\n",
    "\n",
    "Create a Embedding layer and initialize its weight. Initial weight parameters are\n",
    "sampled from normal distribution scaled by a `scale` factor.\n",
    "\n",
    "# Examples\n",
    "```julia-repl\n",
    "julia> embed = Embedding(100, 25);\n",
    "\n",
    "julia> x = rand(1:10, 10);\n",
    "\n",
    "julia> embed(x); # forward call\n",
    "```\n",
    "\"\"\"\n",
    "mutable struct Embedding\n",
    "    w # weight\n",
    "end\n",
    "\n",
    "function Embedding(vocabsize::Int, embedsize::Int, atype=_atype, scale=0.01)\n",
    "    w = Param(convert(atype, scale*randn(embedsize, vocabsize)));\n",
    "    return Embedding(w)\n",
    "end\n",
    "\n",
    "\n",
    "function (l::Embedding)(x)\n",
    "    l.w[:, x]\n",
    "end\n",
    "\n",
    "@info \"Testing embedding layer\"\n",
    "Random.seed!(1)\n",
    "embed = Embedding(100, 25);\n",
    "x = rand(1:25, 12, 32);\n",
    "@test size(embed(x)) == (25, 12, 32)\n",
    "@test sum(embed(x)) ≈ -4.231335f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing linear layer\n",
      "└ @ Main In[10]:32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Linear(inputsize, outputsize; atype=Array{Float64}, scale::Float64=0.1)\n",
    "\n",
    "Create a linear layer with its weight and bias. Initial weight parameters are\n",
    "sampled from normal distribution scaled by a `scale` factor. Initial bias\n",
    "values are zeros.\n",
    "\n",
    "# Examples\n",
    "```julia-repl\n",
    "julia> layer = Linear(50, 10);\n",
    "\n",
    "julia> x = rand(2, 50);\n",
    "\n",
    "julia> layer(x); # forward call\n",
    "```\n",
    "\"\"\"\n",
    "mutable struct Linear\n",
    "    w # weight\n",
    "    b # bias\n",
    "\n",
    "    function Linear(inputsize, outputsize; atype=_atype, scale::Float64=0.01)\n",
    "        w = Param(convert(atype, scale*randn(outputsize, inputsize)));\n",
    "        b = Param(convert(atype, zeros(outputsize)));\n",
    "        new(w, b)\n",
    "    end\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    l.w * x .+ l.b\n",
    "end\n",
    "\n",
    "@info \"Testing linear layer\"\n",
    "Random.seed!(1)\n",
    "lin = Linear(100, 200);\n",
    "x = _atype(randn(100, 32));\n",
    "@test size(lin(x)) == (200, 32)\n",
    "@test sum(lin(x)) ≈ -3.8317218f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing hidden layer\n",
      "└ @ Main In[11]:33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Hidden(inputsize, outputsize, fun=relu, atype=_atype, scale=0.1)\n",
    "\n",
    "Create a hidden layer with its weight and bias and activation function. Initial weight parameters are\n",
    "sampled from normal distribution scaled by a `scale` factor. Initial bias\n",
    "values are zeros.\n",
    "\n",
    "# Examples\n",
    "```julia-repl\n",
    "julia> layer = Hidden(100, 200);\n",
    "\n",
    "julia> x = rand(100, 5);\n",
    "\n",
    "julia> layer(x); # forward call\n",
    "```\n",
    "\"\"\"\n",
    "mutable struct Hidden\n",
    "    w # weight\n",
    "    b # bias\n",
    "    fun # non-linear activation function like relu or tanh\n",
    "\n",
    "    function Hidden(inputsize, outputsize, fun=relu, atype=_atype, scale=0.1)\n",
    "        w = Param(convert(atype, scale*randn(outputsize, inputsize)));\n",
    "        b = Param(convert(atype, zeros(outputsize)));\n",
    "        new(w, b, fun)\n",
    "    end\n",
    "end\n",
    "\n",
    "function (l::Hidden)(x)\n",
    "    l.fun.(l.w * x .+ l.b)\n",
    "end\n",
    "\n",
    "@info \"Testing hidden layer\"\n",
    "Random.seed!(1)\n",
    "hid = Hidden(200, 256);\n",
    "x = _atype(randn(200, 32));\n",
    "@test size(hid(x)) == (256, 32)\n",
    "@test sum(hid(x)) ≈ 4635.545f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tagger model\n",
    "\n",
    "Our model consists of four layers. Size of their outputs are as the following:\n",
    "* **(T)** - Input\n",
    "* **(E, T)** - Embedding\n",
    "* **(RNN, T)** - RNN\n",
    "* **(H, T)** - Hidden\n",
    "* **(NTags, T)** - Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing forward pass of NERTagger\n",
      "└ @ Main In[12]:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[12]:27\u001b[22m\n",
      "  Expression: sum(output) == 1.512398f0\n",
      "   Evaluated: 1.5123978f0 == 1.512398f0\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "There was an error during testing",
     "output_type": "error",
     "traceback": [
      "There was an error during testing",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[12]:27",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "mutable struct NERTagger\n",
    "    embed::Embedding\n",
    "    rnn::RNN\n",
    "    hidden::Hidden\n",
    "    projection::Linear\n",
    "end\n",
    "\n",
    "function NERTagger(no_words, no_tags, embed_size, rnn_hidden_size, mlp_hidden_size, atype=_atype)\n",
    "    embed = Embedding(no_words, embed_size, atype)\n",
    "    rnn = RNN(embed_size, rnn_hidden_size)\n",
    "    hidden = Hidden(rnn_hidden_size, mlp_hidden_size)\n",
    "    projection = Linear(mlp_hidden_size, no_tags; atype = atype)\n",
    "    return NERTagger(embed, rnn, hidden, projection)\n",
    "end\n",
    "\n",
    "function (m::NERTagger)(x; batchsizes=nothing)\n",
    "    m.projection(m.hidden(m.rnn(m.embed(x); batchSizes = batchsizes)))\n",
    "end\n",
    "\n",
    "@info \"Testing forward pass of NERTagger\"\n",
    "Random.seed!(1)\n",
    "nwords, ntags = length(data.w2i), data.ntags\n",
    "model = NERTagger(nwords, ntags, 128, 50, 32)\n",
    "\n",
    "output = model(words; batchsizes=batchsizes)\n",
    "@test size(output) == (9, 397)\n",
    "@test sum(output) == 1.512398f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will implement loss function for your model.\n",
    "Firstly get your probabilities from your model.\n",
    "Then calculate the loss function for average per token. You can use `nll` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing loss function of NERTagger\n",
      "└ @ Main In[13]:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function (m::NERTagger)(x, ygold, batchsizes, average=true)\n",
    "   nll(m(x; batchsizes = batchsizes), ygold; average = average)\n",
    "end\n",
    "\n",
    "@info \"Testing loss function of NERTagger\"\n",
    "Random.seed!(1)\n",
    "nwords, ntags = length(data.w2i), data.ntags\n",
    "model = NERTagger(nwords, ntags, 128, 50, 32)\n",
    "l = model(words, tags, batchsizes)\n",
    "\n",
    "@test l ≈ 2.1969666f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss for a whole dataset\n",
    "\n",
    "Define a `loss(model, data)` which returns a `(Σloss, Nloss)` pair if `average=false` and\n",
    "a `Σloss/Nloss` average if `average=true` for a whole dataset. Assume that `data` is an\n",
    "iterator of `(words, gold_tags, batchsizes)` such as `WikiNERProcessed` and `model(x,y;average)` is a model like\n",
    "`NERTagger` that computes loss on a single `(x,y)` pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing loss function\n",
      "└ @ Main In[14]:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[14]:21\u001b[22m\n",
      "  Expression: loss(model, devdata; average = false) == (85688.48f0, 39007)\n",
      "   Evaluated: (85075.47f0, 38728) == (85688.48f0, 39007)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "There was an error during testing",
     "output_type": "error",
     "traceback": [
      "There was an error during testing",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[14]:21",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    loss(model::NERTagger, data; average=true)\n",
    "\n",
    "Return overall loss of model on data.\n",
    "\"\"\"\n",
    "function loss(model::NERTagger, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    \n",
    "    for (x, y, b) in data\n",
    "        loss,number = model(x,y,b,false)\n",
    "        l += loss\n",
    "        n += number\n",
    "    end\n",
    "    average && return l / n\n",
    "    return l, n\n",
    "end\n",
    "@info \"Testing loss function\"\n",
    "Random.seed!(1)\n",
    "@test loss(model, devdata) ≈ 2.196791f0\n",
    "@test loss(model, devdata; average=false) == (85688.48f0, 39007)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "Why are we getting such value for loss? is this expected and why?\n",
    "\n",
    "Write your answer here:\n",
    "\n",
    "- Due to the nature of the negative log likelihood, one can expect that the loss value in the beginning should be $ln(n_{classes})$, since all parameters are randomly initialized. In our case, one can expect that $loss = ln(9) \\approx 2.196$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy metric\n",
    "This function will be the metric which will evaluate our model's performance.\n",
    "\n",
    "You will iterate over the given `data` object, predicting each instance and adding number of correctly predicted tokens to `ncorrect` and the number of tokens to `ntokens`.\n",
    "\n",
    "possible helpful procedures: `argmax`, `vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing accuracy function\n",
      "└ @ Main In[15]:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[15]:24\u001b[22m\n",
      "  Expression: accuracy(model, devdata, data.i2t) ≈ 0.1758145973799\n",
      "   Evaluated: 0.17628072712249535 ≈ 0.1758145973799\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "There was an error during testing",
     "output_type": "error",
     "traceback": [
      "There was an error during testing",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[15]:24",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    accuracy(model::NERTagger, data, i2t)\n",
    "\n",
    "Return accuracy of tags given a model and dataset\n",
    "\"\"\"\n",
    "function accuracy(model::NERTagger, data, i2t)\n",
    "    ncorrect = 0\n",
    "    ntokens = 0\n",
    "\n",
    "    for (x, ygold, batchsizes) in data\n",
    "        scores = model(x; batchsizes=batchsizes)\n",
    "        # Your answer here\n",
    "        ntokens += length(ygold)\n",
    "        ypred = map( y -> y[1], argmax(scores, dims=1))\n",
    "        ncorrect += sum(ygold .== ypred')\n",
    "        # Your answer here\n",
    "    end\n",
    "\n",
    "    return ncorrect / ntokens\n",
    "end\n",
    "\n",
    "@info \"Testing accuracy function\"\n",
    "@test accuracy(model, devdata, data.i2t) ≈ 0.1758145973799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to train our model. trn is the training data, dev is used to determine the best model, tst... can be zero or more small test datasets for loss reporting. It returns the model that does best on dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Knet.Train20.train!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    train!(model, trn, dev, tst...)\n",
    "\n",
    "Train `model` on `trn` data with Adam optimizer and Return the best performing model on `dev` data.\n",
    "\"\"\"\n",
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), steps=1000) do y\n",
    "        losses = [ loss(model, d) for d in (dev,tst...) ]\n",
    "        if losses[1] < bestloss\n",
    "            bestmodel, bestloss = deepcopy(model), losses[1]\n",
    "        end\n",
    "        return (losses...,)\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Here we train our model for 10 epochs using the previous procedure. You can try to fiddle with the hyperparameters i.e. (embed_size, hidden_size, epochs, etc..) to get better loss on dev set. You should get a value of dev loss around `0.26`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training NERTagger model\n",
      "└ @ Main In[17]:1\n",
      "┌ Info: Seeding random number generator\n",
      "└ @ Main In[17]:2\n",
      "┌ Info: Loading data\n",
      "└ @ Main In[17]:5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 1\n",
      "nwords = 28484\n",
      "ntags = 9\n",
      "embed_size = 128\n",
      "rnn_size = 50\n",
      "hidden_size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Initializing model\n",
      "└ @ Main In[17]:15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NERTagger(Embedding(P(KnetArray{Float32,2}(128,28484))), LSTM(input=128,hidden=50), Hidden(P(KnetArray{Float32,2}(32,50)), P(KnetArray{Float32,1}(32)), Knet.Ops20.relu), Linear(P(KnetArray{Float32,2}(9,32)), P(KnetArray{Float32,1}(9))))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Training NERTagger model\"\n",
    "@info \"Seeding random number generator\"\n",
    "Random.seed!(1)\n",
    "\n",
    "@info \"Loading data\"\n",
    "data = WikiNERData();\n",
    "dtrn = WikiNERProcessed(data.trn, data.w2i, data.t2i);\n",
    "ddev = WikiNERProcessed(data.dev, data.w2i, data.t2i; shuffled=false);\n",
    "epochs = 1; @show epochs\n",
    "ctrn = [ b for b in dtrn ]\n",
    "trnx10 = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "trn20 = ctrn[1:20]\n",
    "dev = [ b for b in ddev ]\n",
    "\n",
    "@info \"Initializing model\"\n",
    "\n",
    "@show nwords\n",
    "@show ntags\n",
    "embed_size = 128; @show embed_size\n",
    "rnn_size = 50; @show rnn_size\n",
    "hidden_size = 32; @show hidden_size\n",
    "model = NERTagger(nwords, ntags, embed_size, rnn_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████████┫ [100.00%, 8883/8883, 01:38/01:38, 90.34i/s] (0.2469082f0, 0.11470737f0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NERTagger(Embedding(P(KnetArray{Float32,2}(128,28484))), LSTM(input=128,hidden=50), Hidden(P(KnetArray{Float32,2}(32,50)), P(KnetArray{Float32,1}(32)), Knet.Ops20.relu), Linear(P(KnetArray{Float32,2}(9,32)), P(KnetArray{Float32,1}(9))))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncomment this to train the model (one epoch should take around 2 mins on gpu):\n",
    "model = train!(model, trnx10, dev, trn20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the best model\n",
    "**Expected Values**\n",
    "- Development loss = 0.25991333\n",
    "- Development accuracy = 0.9176301689440357\n",
    "- Training loss = 0.11450425\n",
    "- Training accuracy = 0.9643299845754065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Evaluating the model\n",
      "└ @ Main In[20]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development loss = 0.2469082\n",
      "Development accuracy = 0.9191799215038216\n",
      "Training loss = 0.111691974\n",
      "Training accuracy = 0.9652775832749825\n"
     ]
    }
   ],
   "source": [
    "@info \"Evaluating the model\"\n",
    "\n",
    "dloss = loss(model, ddev)\n",
    "tloss = loss(model, dtrn)\n",
    "dacc = accuracy(model, ddev, data.i2t)\n",
    "tacc = accuracy(model, dtrn, data.i2t)\n",
    "\n",
    "println(\"Development loss = \", dloss)\n",
    "println(\"Development accuracy = \", dacc)\n",
    "println(\"Training loss = \", tloss)\n",
    "println(\"Training accuracy = \", tacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
